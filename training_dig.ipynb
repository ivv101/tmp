{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pUnlnXGt2NET"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 15:41:08.599133: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 15:41:09.097960: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ivv101/arrayfire/lib64:/usr/local/cuda/lib64:/home/ivv101/arrayfire/lib64:/usr/local/cuda/lib64::/home/ivv101/miniconda3/envs/p310/lib/:/home/ivv101/miniconda3/envs/p310/lib/\n",
      "2023-02-05 15:41:09.098057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ivv101/arrayfire/lib64:/usr/local/cuda/lib64:/home/ivv101/arrayfire/lib64:/usr/local/cuda/lib64::/home/ivv101/miniconda3/envs/p310/lib/:/home/ivv101/miniconda3/envs/p310/lib/\n",
      "2023-02-05 15:41:09.098063: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle as pkl\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import autokeras as ak # !pip install autokeras\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "\n",
    "# import datetime\n",
    "# import hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "# %env CLEARML_API_HOST=https://api.clear.ml\n",
    "# %env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "# %env CLEARML_API_ACCESS_KEY=Z0Z7YQU3HMJI84E6VJFE\n",
    "# %env CLEARML_API_SECRET_KEY=GLBnwfxSOb2lzWDibL9uHR5FQwg5bAKFxBllsYMUwB8ljyZtrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from clearml import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = Task.init(project_name='great project', task_name='best experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 321 #165 #321 #434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(out_dir):\n",
    "#     os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_features = ['Fs', 'Fm', 'Fh', 'Fb', \n",
    "                'rgeo', 'b_rgeo', 'B_rgeo',\n",
    "                'PM'\n",
    "               ]\n",
    "\n",
    "features = ['Fs', 'Fm', 'Fh', 'Fb',\n",
    "            'P_intra', 'P_inter',\n",
    "            'Gmag', 'BPmag', 'RPmag', 'Jmag', 'Hmag', 'Kmag',\n",
    "            'W1mag', 'W2mag', 'W3mag',\n",
    "            'Plx', 'PM',\n",
    "            'rgeo', 'b_rgeo', 'B_rgeo'\n",
    "           ]\n",
    "\n",
    "errors = ['e_Fs', 'e_Fm', 'e_Fh', 'e_Fb',\n",
    "          'e_Gmag', 'e_BPmag', 'e_RPmag', 'e_Jmag', 'e_Hmag', 'e_Kmag',\n",
    "          'e_W1mag', 'e_W2mag', 'e_W3mag', \n",
    "          'e_Plx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSCv2_name</th>\n",
       "      <th>CSCv2_RA</th>\n",
       "      <th>CSCv2_DEC</th>\n",
       "      <th>CSCv2_PU</th>\n",
       "      <th>CSCv2_S/N</th>\n",
       "      <th>Fs</th>\n",
       "      <th>e_Fs</th>\n",
       "      <th>Fm</th>\n",
       "      <th>e_Fm</th>\n",
       "      <th>Fh</th>\n",
       "      <th>...</th>\n",
       "      <th>e_P_NS</th>\n",
       "      <th>e_P_YSO</th>\n",
       "      <th>Class</th>\n",
       "      <th>Class_prob</th>\n",
       "      <th>e_Class_prob</th>\n",
       "      <th>CT</th>\n",
       "      <th>CSCv2_flags</th>\n",
       "      <th>Catalog_name</th>\n",
       "      <th>True_Class</th>\n",
       "      <th>Class_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2CXO J000009.3+135618</td>\n",
       "      <td>0.039115</td>\n",
       "      <td>13.938493</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.95</td>\n",
       "      <td>-14.698970</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>-15.301030</td>\n",
       "      <td>5.000000e-16</td>\n",
       "      <td>-14.698970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>AGN</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.100</td>\n",
       "      <td>5.307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SDSS J00001+1356</td>\n",
       "      <td>AGN</td>\n",
       "      <td>2010A&amp;A...518A..10V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2CXO J000230.7+004959</td>\n",
       "      <td>0.627974</td>\n",
       "      <td>0.833072</td>\n",
       "      <td>0.72</td>\n",
       "      <td>11.07</td>\n",
       "      <td>-13.244125</td>\n",
       "      <td>7.000000e-15</td>\n",
       "      <td>-13.537602</td>\n",
       "      <td>5.000000e-15</td>\n",
       "      <td>-13.221849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>AGN</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.004</td>\n",
       "      <td>145.799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PB 5698</td>\n",
       "      <td>AGN</td>\n",
       "      <td>2010A&amp;A...518A..10V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2CXO J000622.6-000424</td>\n",
       "      <td>1.594324</td>\n",
       "      <td>-0.073573</td>\n",
       "      <td>0.78</td>\n",
       "      <td>25.42</td>\n",
       "      <td>-12.823909</td>\n",
       "      <td>1.000000e-14</td>\n",
       "      <td>-12.931814</td>\n",
       "      <td>8.000000e-15</td>\n",
       "      <td>-12.397940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>AGN</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.020</td>\n",
       "      <td>20.820</td>\n",
       "      <td>extent</td>\n",
       "      <td>3C   2.0</td>\n",
       "      <td>AGN</td>\n",
       "      <td>2010A&amp;A...518A..10V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2CXO J000659.2-001740</td>\n",
       "      <td>1.747051</td>\n",
       "      <td>-0.294661</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4.11</td>\n",
       "      <td>-13.958607</td>\n",
       "      <td>4.000000e-15</td>\n",
       "      <td>-14.221849</td>\n",
       "      <td>3.000000e-15</td>\n",
       "      <td>-13.853872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>AGN</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.060</td>\n",
       "      <td>8.318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SDSS J00069-0017</td>\n",
       "      <td>AGN</td>\n",
       "      <td>2010A&amp;A...518A..10V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2CXO J000703.6+155423</td>\n",
       "      <td>1.765007</td>\n",
       "      <td>15.906575</td>\n",
       "      <td>0.72</td>\n",
       "      <td>8.63</td>\n",
       "      <td>-14.301030</td>\n",
       "      <td>3.000000e-15</td>\n",
       "      <td>-13.795880</td>\n",
       "      <td>6.000000e-15</td>\n",
       "      <td>-12.267606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>AGN</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.010</td>\n",
       "      <td>47.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2MASS J00070+1554</td>\n",
       "      <td>AGN</td>\n",
       "      <td>2010A&amp;A...518A..10V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>2CXO J183000.6+011340</td>\n",
       "      <td>277.502734</td>\n",
       "      <td>1.227794</td>\n",
       "      <td>0.71</td>\n",
       "      <td>20.82</td>\n",
       "      <td>-14.657577</td>\n",
       "      <td>4.000000e-16</td>\n",
       "      <td>-13.795880</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>-13.200659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>YSO</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.030</td>\n",
       "      <td>16.735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2MASS J18300065+0113402</td>\n",
       "      <td>YSO</td>\n",
       "      <td>2007A&amp;A...463..275G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>2CXO J183001.1+011324</td>\n",
       "      <td>277.504621</td>\n",
       "      <td>1.223367</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.10</td>\n",
       "      <td>-16.154902</td>\n",
       "      <td>7.000000e-17</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>3.000000e-16</td>\n",
       "      <td>-13.795880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>YSO</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.090</td>\n",
       "      <td>3.192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2MASS J18300111+0113242</td>\n",
       "      <td>YSO</td>\n",
       "      <td>2007A&amp;A...463..275G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>2CXO J183003.4+011619</td>\n",
       "      <td>277.514213</td>\n",
       "      <td>1.271981</td>\n",
       "      <td>0.73</td>\n",
       "      <td>13.69</td>\n",
       "      <td>-14.508638</td>\n",
       "      <td>5.000000e-16</td>\n",
       "      <td>-14.136677</td>\n",
       "      <td>8.000000e-16</td>\n",
       "      <td>-13.744727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>YSO</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.005</td>\n",
       "      <td>124.848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2MASS J18300341+0116191</td>\n",
       "      <td>YSO</td>\n",
       "      <td>2007A&amp;A...463..275G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>2CXO J183007.7+011204</td>\n",
       "      <td>277.532159</td>\n",
       "      <td>1.201211</td>\n",
       "      <td>0.75</td>\n",
       "      <td>15.60</td>\n",
       "      <td>-14.420216</td>\n",
       "      <td>6.000000e-16</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>-13.619789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>YSO</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.007</td>\n",
       "      <td>84.887</td>\n",
       "      <td>extent</td>\n",
       "      <td>2MASS J18300770+0112043</td>\n",
       "      <td>YSO</td>\n",
       "      <td>2007A&amp;A...463..275G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>2CXO J183011.1+011237</td>\n",
       "      <td>277.546341</td>\n",
       "      <td>1.210521</td>\n",
       "      <td>0.73</td>\n",
       "      <td>39.96</td>\n",
       "      <td>-13.657577</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>-13.180456</td>\n",
       "      <td>2.000000e-15</td>\n",
       "      <td>-12.657577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>LMXB</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1.452</td>\n",
       "      <td>extent</td>\n",
       "      <td>2MASS J18301111+0112379</td>\n",
       "      <td>YSO</td>\n",
       "      <td>2007A&amp;A...463..275G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2941 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CSCv2_name    CSCv2_RA  CSCv2_DEC  CSCv2_PU  CSCv2_S/N  \\\n",
       "0     2CXO J000009.3+135618    0.039115  13.938493      0.79       1.95   \n",
       "1     2CXO J000230.7+004959    0.627974   0.833072      0.72      11.07   \n",
       "2     2CXO J000622.6-000424    1.594324  -0.073573      0.78      25.42   \n",
       "3     2CXO J000659.2-001740    1.747051  -0.294661      0.84       4.11   \n",
       "4     2CXO J000703.6+155423    1.765007  15.906575      0.72       8.63   \n",
       "...                     ...         ...        ...       ...        ...   \n",
       "2936  2CXO J183000.6+011340  277.502734   1.227794      0.71      20.82   \n",
       "2937  2CXO J183001.1+011324  277.504621   1.223367      0.75       8.10   \n",
       "2938  2CXO J183003.4+011619  277.514213   1.271981      0.73      13.69   \n",
       "2939  2CXO J183007.7+011204  277.532159   1.201211      0.75      15.60   \n",
       "2940  2CXO J183011.1+011237  277.546341   1.210521      0.73      39.96   \n",
       "\n",
       "             Fs          e_Fs         Fm          e_Fm         Fh  ...  \\\n",
       "0    -14.698970  1.000000e-15 -15.301030  5.000000e-16 -14.698970  ...   \n",
       "1    -13.244125  7.000000e-15 -13.537602  5.000000e-15 -13.221849  ...   \n",
       "2    -12.823909  1.000000e-14 -12.931814  8.000000e-15 -12.397940  ...   \n",
       "3    -13.958607  4.000000e-15 -14.221849  3.000000e-15 -13.853872  ...   \n",
       "4    -14.301030  3.000000e-15 -13.795880  6.000000e-15 -12.267606  ...   \n",
       "...         ...           ...        ...           ...        ...  ...   \n",
       "2936 -14.657577  4.000000e-16 -13.795880  1.000000e-15 -13.200659  ...   \n",
       "2937 -16.154902  7.000000e-17 -15.000000  3.000000e-16 -13.795880  ...   \n",
       "2938 -14.508638  5.000000e-16 -14.136677  8.000000e-16 -13.744727  ...   \n",
       "2939 -14.420216  6.000000e-16 -14.000000  1.000000e-15 -13.619789  ...   \n",
       "2940 -13.657577  1.000000e-15 -13.180456  2.000000e-15 -12.657577  ...   \n",
       "\n",
       "      e_P_NS  e_P_YSO  Class  Class_prob  e_Class_prob       CT  CSCv2_flags  \\\n",
       "0     0.0040   0.0500    AGN       0.900         0.100    5.307          NaN   \n",
       "1     0.0003   0.0004    AGN       0.999         0.004  145.799          NaN   \n",
       "2     0.0050   0.0009    AGN       0.970         0.020   20.820       extent   \n",
       "3     0.0030   0.0070    AGN       0.950         0.060    8.318          NaN   \n",
       "4     0.0004   0.0090    AGN       0.990         0.010   47.057          NaN   \n",
       "...      ...      ...    ...         ...           ...      ...          ...   \n",
       "2936  0.0010   0.0300    YSO       0.930         0.030   16.735          NaN   \n",
       "2937  0.0010   0.0900    YSO       0.800         0.090    3.192          NaN   \n",
       "2938  0.0000   0.0050    YSO       0.998         0.005  124.848          NaN   \n",
       "2939  0.0000   0.0070    YSO       0.996         0.007   84.887       extent   \n",
       "2940  0.0100   0.0500   LMXB       0.410         0.070    1.452       extent   \n",
       "\n",
       "                 Catalog_name  True_Class            Class_ref  \n",
       "0            SDSS J00001+1356         AGN  2010A&A...518A..10V  \n",
       "1                     PB 5698         AGN  2010A&A...518A..10V  \n",
       "2                    3C   2.0         AGN  2010A&A...518A..10V  \n",
       "3            SDSS J00069-0017         AGN  2010A&A...518A..10V  \n",
       "4           2MASS J00070+1554         AGN  2010A&A...518A..10V  \n",
       "...                       ...         ...                  ...  \n",
       "2936  2MASS J18300065+0113402         YSO  2007A&A...463..275G  \n",
       "2937  2MASS J18300111+0113242         YSO  2007A&A...463..275G  \n",
       "2938  2MASS J18300341+0116191         YSO  2007A&A...463..275G  \n",
       "2939  2MASS J18300770+0112043         YSO  2007A&A...463..275G  \n",
       "2940  2MASS J18301111+0112379         YSO  2007A&A...463..275G  \n",
       "\n",
       "[2941 rows x 63 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TD.csv')\n",
    "df[log_features] = df[log_features].apply(np.log10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {f: [df[f].min(), df[f].max()] for f in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = df[features].apply(lambda x : (x-x.mean())/x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fs': [-2.576097051867796, 3.037547888651721],\n",
       " 'Fm': [-3.1633175259424413, 3.353068673263792],\n",
       " 'Fh': [-3.167529234962109, 3.6737353736479137],\n",
       " 'Fb': [-2.359584277219483, 4.031512746439284],\n",
       " 'P_intra': [-2.292931596557009, 0.9472948406444076],\n",
       " 'P_inter': [-3.0385115023161156, 0.6455515963566589],\n",
       " 'Gmag': [-4.196046959939427, 1.5323452993212447],\n",
       " 'BPmag': [-4.0727319624873894, 1.731833276730117],\n",
       " 'RPmag': [-4.124723888688924, 1.6909016342756864],\n",
       " 'Jmag': [-4.425041079460414, 2.124007095008807],\n",
       " 'Hmag': [-4.71265263641138, 2.3305540821294275],\n",
       " 'Kmag': [-4.862626877029222, 2.3155364970244823],\n",
       " 'W1mag': [-4.481634646882916, 1.9060303148077884],\n",
       " 'W2mag': [-4.555152917342131, 2.0219436807633633],\n",
       " 'W3mag': [-6.329868656158829, 1.6005678318859842],\n",
       " 'Plx': [-2.4774673348866676, 13.867643841820009],\n",
       " 'PM': [-3.5940296284202304, 2.597799702665246],\n",
       " 'rgeo': [-3.0630369317925497, 2.322108818082452],\n",
       " 'b_rgeo': [-3.20847676381954, 2.6005180022943195],\n",
       " 'B_rgeo': [-2.9034591466815143, 2.3233648115374446]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{f: [df_feat[f].min(), df_feat[f].max()] for f in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.arange(df_feat.min().min(), df_feat.max().max(), 0.1)\n",
    "\n",
    "# df_dig = df_feat.apply(lambda x : np.digitize(x, bins))\n",
    "# df_dig[df_feat.isna()] = 0\n",
    "\n",
    "# tf_dig = tf.constant(df_dig, dtype=tf.int32)\n",
    "\n",
    "# len(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fs          0.000000\n",
      "Fm          0.000000\n",
      "Fh          0.000000\n",
      "Fb          0.000000\n",
      "P_intra     7.446447\n",
      "P_inter    54.403264\n",
      "Gmag       24.311459\n",
      "BPmag      25.127508\n",
      "RPmag      24.957497\n",
      "Jmag       37.980279\n",
      "Hmag       37.980279\n",
      "Kmag       37.980279\n",
      "W1mag      23.937436\n",
      "W2mag      24.651479\n",
      "W3mag      38.796328\n",
      "Plx        32.709963\n",
      "PM         32.709963\n",
      "rgeo       32.709963\n",
      "b_rgeo     32.709963\n",
      "B_rgeo     32.709963\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((df_feat.isna().sum()/len(df_feat)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'AGN': 1390,\n",
       "         'CV': 44,\n",
       "         'HM-STAR': 118,\n",
       "         'YSO': 1004,\n",
       "         'HMXB': 26,\n",
       "         'LMXB': 65,\n",
       "         'LM-STAR': 207,\n",
       "         'NS': 87})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['True_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AGN       0.98      0.93      0.95      1390\n",
      "          CV       0.48      0.55      0.51        44\n",
      "     HM-STAR       0.67      0.72      0.69       118\n",
      "        HMXB       0.75      0.69      0.72        26\n",
      "     LM-STAR       0.81      0.86      0.84       207\n",
      "        LMXB       0.19      0.26      0.22        65\n",
      "          NS       0.51      0.68      0.58        87\n",
      "         YSO       0.93      0.94      0.93      1004\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2941\n",
      "   macro avg       0.67      0.70      0.68      2941\n",
      "weighted avg       0.90      0.89      0.89      2941\n",
      " samples avg       0.89      0.89      0.89      2941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlb = LabelBinarizer()\n",
    "\n",
    "y_true = mlb.fit_transform(df['True_Class'])\n",
    "y_pred_hui = mlb.transform(df['Class'])\n",
    "\n",
    "classes = mlb.classes_\n",
    "\n",
    "# classes, labels.shape\n",
    "\n",
    "print(classification_report(y_true, y_pred_hui, \n",
    "                            output_dict=False,\n",
    "                            target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_y_true = tf.constant(y_true, dtype=tf.int32)\n",
    "# tf_y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fs</th>\n",
       "      <th>Fm</th>\n",
       "      <th>Fh</th>\n",
       "      <th>Fb</th>\n",
       "      <th>P_intra</th>\n",
       "      <th>P_inter</th>\n",
       "      <th>Gmag</th>\n",
       "      <th>BPmag</th>\n",
       "      <th>RPmag</th>\n",
       "      <th>Jmag</th>\n",
       "      <th>Hmag</th>\n",
       "      <th>Kmag</th>\n",
       "      <th>W1mag</th>\n",
       "      <th>W2mag</th>\n",
       "      <th>W3mag</th>\n",
       "      <th>Plx</th>\n",
       "      <th>PM</th>\n",
       "      <th>rgeo</th>\n",
       "      <th>b_rgeo</th>\n",
       "      <th>B_rgeo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.199449</td>\n",
       "      <td>-1.033569</td>\n",
       "      <td>-0.741320</td>\n",
       "      <td>-0.973895</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492168</td>\n",
       "      <td>0.535112</td>\n",
       "      <td>0.746560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853763</td>\n",
       "      <td>0.826402</td>\n",
       "      <td>0.487181</td>\n",
       "      <td>-0.742511</td>\n",
       "      <td>-1.095253</td>\n",
       "      <td>1.198046</td>\n",
       "      <td>1.122459</td>\n",
       "      <td>1.536628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.242478</td>\n",
       "      <td>1.057694</td>\n",
       "      <td>0.753216</td>\n",
       "      <td>0.928074</td>\n",
       "      <td>-1.262540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.288212</td>\n",
       "      <td>0.335138</td>\n",
       "      <td>0.531072</td>\n",
       "      <td>1.445468</td>\n",
       "      <td>1.631887</td>\n",
       "      <td>1.702818</td>\n",
       "      <td>0.548266</td>\n",
       "      <td>0.363090</td>\n",
       "      <td>0.268411</td>\n",
       "      <td>-0.514228</td>\n",
       "      <td>-1.089332</td>\n",
       "      <td>0.626017</td>\n",
       "      <td>0.611672</td>\n",
       "      <td>0.782127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.658963</td>\n",
       "      <td>1.776103</td>\n",
       "      <td>1.586837</td>\n",
       "      <td>1.765626</td>\n",
       "      <td>-2.046674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969920</td>\n",
       "      <td>0.969431</td>\n",
       "      <td>1.193379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.795132</td>\n",
       "      <td>0.706524</td>\n",
       "      <td>0.643446</td>\n",
       "      <td>-0.651198</td>\n",
       "      <td>-2.149547</td>\n",
       "      <td>0.370039</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.403904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.534340</td>\n",
       "      <td>0.246240</td>\n",
       "      <td>0.113741</td>\n",
       "      <td>0.121539</td>\n",
       "      <td>-0.290472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722391</td>\n",
       "      <td>0.706965</td>\n",
       "      <td>1.015919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.180861</td>\n",
       "      <td>1.163357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.107765</td>\n",
       "      <td>-0.699429</td>\n",
       "      <td>0.800462</td>\n",
       "      <td>0.759952</td>\n",
       "      <td>0.929681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194958</td>\n",
       "      <td>0.751400</td>\n",
       "      <td>1.718708</td>\n",
       "      <td>1.669686</td>\n",
       "      <td>-1.855501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.493095</td>\n",
       "      <td>0.407004</td>\n",
       "      <td>0.337767</td>\n",
       "      <td>0.820297</td>\n",
       "      <td>0.852450</td>\n",
       "      <td>0.694386</td>\n",
       "      <td>-0.343539</td>\n",
       "      <td>-0.476057</td>\n",
       "      <td>-0.731684</td>\n",
       "      <td>-0.559884</td>\n",
       "      <td>-0.458692</td>\n",
       "      <td>0.897704</td>\n",
       "      <td>0.625411</td>\n",
       "      <td>0.868525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>-0.158424</td>\n",
       "      <td>0.751400</td>\n",
       "      <td>0.774655</td>\n",
       "      <td>0.635347</td>\n",
       "      <td>0.947295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985371</td>\n",
       "      <td>1.263144</td>\n",
       "      <td>0.819445</td>\n",
       "      <td>0.096013</td>\n",
       "      <td>-0.407573</td>\n",
       "      <td>-0.599130</td>\n",
       "      <td>-0.942189</td>\n",
       "      <td>-0.916690</td>\n",
       "      <td>-0.419154</td>\n",
       "      <td>0.535877</td>\n",
       "      <td>1.124639</td>\n",
       "      <td>-0.078631</td>\n",
       "      <td>-0.521381</td>\n",
       "      <td>0.104488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>-1.642453</td>\n",
       "      <td>-0.676575</td>\n",
       "      <td>0.172417</td>\n",
       "      <td>-0.199851</td>\n",
       "      <td>0.947295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.838106</td>\n",
       "      <td>1.304766</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>-0.436114</td>\n",
       "      <td>-0.702853</td>\n",
       "      <td>-0.790283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>-0.010807</td>\n",
       "      <td>0.347246</td>\n",
       "      <td>0.224173</td>\n",
       "      <td>0.067089</td>\n",
       "      <td>0.947295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.176562</td>\n",
       "      <td>0.275771</td>\n",
       "      <td>-0.232641</td>\n",
       "      <td>-0.315685</td>\n",
       "      <td>-0.451997</td>\n",
       "      <td>-0.488500</td>\n",
       "      <td>-0.929846</td>\n",
       "      <td>-0.929650</td>\n",
       "      <td>-1.169225</td>\n",
       "      <td>0.357816</td>\n",
       "      <td>1.145793</td>\n",
       "      <td>-0.862243</td>\n",
       "      <td>-0.774274</td>\n",
       "      <td>-0.921537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>0.076830</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>0.350584</td>\n",
       "      <td>0.230456</td>\n",
       "      <td>0.292769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145133</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>-0.327121</td>\n",
       "      <td>-0.536806</td>\n",
       "      <td>-0.620405</td>\n",
       "      <td>-1.081052</td>\n",
       "      <td>-1.149966</td>\n",
       "      <td>-1.149692</td>\n",
       "      <td>0.307594</td>\n",
       "      <td>1.262462</td>\n",
       "      <td>-0.782186</td>\n",
       "      <td>-0.755222</td>\n",
       "      <td>-0.788375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>0.832697</td>\n",
       "      <td>1.481236</td>\n",
       "      <td>1.324139</td>\n",
       "      <td>1.349867</td>\n",
       "      <td>0.947295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.371957</td>\n",
       "      <td>1.044422</td>\n",
       "      <td>0.306078</td>\n",
       "      <td>0.057893</td>\n",
       "      <td>0.125513</td>\n",
       "      <td>0.183788</td>\n",
       "      <td>-0.470058</td>\n",
       "      <td>-0.433938</td>\n",
       "      <td>-0.364462</td>\n",
       "      <td>0.307594</td>\n",
       "      <td>1.227638</td>\n",
       "      <td>-0.804529</td>\n",
       "      <td>-0.744805</td>\n",
       "      <td>-0.838793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2941 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fs        Fm        Fh        Fb   P_intra  P_inter      Gmag  \\\n",
       "0    -0.199449 -1.033569 -0.741320 -0.973895  0.697797      NaN  0.492168   \n",
       "1     1.242478  1.057694  0.753216  0.928074 -1.262540      NaN  0.288212   \n",
       "2     1.658963  1.776103  1.586837  1.765626 -2.046674      NaN  0.969920   \n",
       "3     0.534340  0.246240  0.113741  0.121539 -0.290472      NaN  0.722391   \n",
       "4     0.194958  0.751400  1.718708  1.669686 -1.855501      NaN  0.493095   \n",
       "...        ...       ...       ...       ...       ...      ...       ...   \n",
       "2936 -0.158424  0.751400  0.774655  0.635347  0.947295      NaN  0.985371   \n",
       "2937 -1.642453 -0.676575  0.172417 -0.199851  0.947295      NaN       NaN   \n",
       "2938 -0.010807  0.347246  0.224173  0.067089  0.947295      NaN -0.176562   \n",
       "2939  0.076830  0.509333  0.350584  0.230456  0.292769      NaN  0.145133   \n",
       "2940  0.832697  1.481236  1.324139  1.349867  0.947295      NaN  0.371957   \n",
       "\n",
       "         BPmag     RPmag      Jmag      Hmag      Kmag     W1mag     W2mag  \\\n",
       "0     0.535112  0.746560       NaN       NaN       NaN  0.853763  0.826402   \n",
       "1     0.335138  0.531072  1.445468  1.631887  1.702818  0.548266  0.363090   \n",
       "2     0.969431  1.193379       NaN       NaN       NaN  0.795132  0.706524   \n",
       "3     0.706965  1.015919       NaN       NaN       NaN  1.180861  1.163357   \n",
       "4     0.407004  0.337767  0.820297  0.852450  0.694386 -0.343539 -0.476057   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2936  1.263144  0.819445  0.096013 -0.407573 -0.599130 -0.942189 -0.916690   \n",
       "2937       NaN       NaN  1.838106  1.304766  0.719916 -0.436114 -0.702853   \n",
       "2938  0.275771 -0.232641 -0.315685 -0.451997 -0.488500 -0.929846 -0.929650   \n",
       "2939  0.816326  0.005029 -0.327121 -0.536806 -0.620405 -1.081052 -1.149966   \n",
       "2940  1.044422  0.306078  0.057893  0.125513  0.183788 -0.470058 -0.433938   \n",
       "\n",
       "         W3mag       Plx        PM      rgeo    b_rgeo    B_rgeo  \n",
       "0     0.487181 -0.742511 -1.095253  1.198046  1.122459  1.536628  \n",
       "1     0.268411 -0.514228 -1.089332  0.626017  0.611672  0.782127  \n",
       "2     0.643446 -0.651198 -2.149547  0.370039  0.200022  0.403904  \n",
       "3          NaN -1.107765 -0.699429  0.800462  0.759952  0.929681  \n",
       "4    -0.731684 -0.559884 -0.458692  0.897704  0.625411  0.868525  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "2936 -0.419154  0.535877  1.124639 -0.078631 -0.521381  0.104488  \n",
       "2937 -0.790283       NaN       NaN       NaN       NaN       NaN  \n",
       "2938 -1.169225  0.357816  1.145793 -0.862243 -0.774274 -0.921537  \n",
       "2939 -1.149692  0.307594  1.262462 -0.782186 -0.755222 -0.788375  \n",
       "2940 -0.364462  0.307594  1.227638 -0.804529 -0.744805 -0.838793  \n",
       "\n",
       "[2941 rows x 20 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "cls = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=120,\n",
    "    per_run_time_limit=30,\n",
    "    tmp_folder=\"/tmp/autosklearn_classification_example_tmp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoSklearnClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtime_left_for_this_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mper_run_time_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_configurations_via_metalearning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_class\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Type[AbstractEnsemble] | Literal['default'] | None\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Dict[str, Any] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_nbest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_models_on_disc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3072\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minclude\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Dict[str, List[str]]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Dict[str, List[str]]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'holdout'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresampling_strategy_arguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtmp_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelete_tmp_folder_after_terminate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdask_client\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[dask.distributed.Client]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisable_evaluator_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mget_smac_object_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msmac_scenario_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogging_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetric\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Scorer | Sequence[Scorer] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscoring_functions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[List[Scorer]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mload_models\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mget_trials_callback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'SMACCallback | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdataset_compression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Union[bool, Mapping[str, Any]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mallow_string_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      This class implements the classification task.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Parameters\n",
       "----------\n",
       "time_left_for_this_task : int, optional (default=3600)\n",
       "    Time limit in seconds for the search of appropriate\n",
       "    models. By increasing this value, *auto-sklearn* has a higher\n",
       "    chance of finding better models.\n",
       "\n",
       "per_run_time_limit : int, optional (default=1/10 of time_left_for_this_task)\n",
       "    Time limit for a single call to the machine learning model.\n",
       "    Model fitting will be terminated if the machine learning\n",
       "    algorithm runs over the time limit. Set this value high enough so\n",
       "    that typical machine learning algorithms can be fit on the\n",
       "    training data.\n",
       "\n",
       "initial_configurations_via_metalearning : int, optional (default=25)\n",
       "    Initialize the hyperparameter optimization algorithm with this\n",
       "    many configurations which worked well on previously seen\n",
       "    datasets. Disable if the hyperparameter optimization algorithm\n",
       "    should start from scratch.\n",
       "\n",
       "ensemble_size : int, optional\n",
       "    Number of models added to the ensemble built by *Ensemble\n",
       "    selection from libraries of models*. Models are drawn with\n",
       "    replacement. If set to ``0`` no ensemble is fit.\n",
       "\n",
       "    Deprecated - will be removed in Auto-sklearn 0.16. Please pass\n",
       "    this argument via ``ensemble_kwargs={\"ensemble_size\": int}``\n",
       "    if you want to change the ensemble size for ensemble selection.\n",
       "\n",
       "ensemble_class : Type[AbstractEnsemble] | \"default\", optional (default=\"default\")\n",
       "    Class implementing the post-hoc ensemble algorithm. Set to\n",
       "    ``None`` to disable ensemble building or use :class:`SingleBest`\n",
       "    to obtain only use the single best model instead of an\n",
       "    ensemble.\n",
       "\n",
       "    If set to \"default\" it will use :class:`EnsembleSelection` for\n",
       "    single-objective problems and :class:`MultiObjectiveDummyEnsemble`\n",
       "    for multi-objective problems.\n",
       "\n",
       "ensemble_kwargs : Dict, optional\n",
       "    Keyword arguments that are passed to the ensemble class upon\n",
       "    initialization.\n",
       "\n",
       "ensemble_nbest : int, optional (default=50)\n",
       "    Only consider the ``ensemble_nbest`` models when building an\n",
       "    ensemble. This is inspired by a concept called library pruning\n",
       "    introduced in `Getting Most out of Ensemble Selection`. This\n",
       "    is independent of the ``ensemble_class`` argument and this\n",
       "    pruning step is done prior to constructing an ensemble.\n",
       "\n",
       "max_models_on_disc: int, optional (default=50),\n",
       "    Defines the maximum number of models that are kept in the disc.\n",
       "    The additional number of models are permanently deleted. Due to the\n",
       "    nature of this variable, it sets the upper limit on how many models\n",
       "    can be used for an ensemble.\n",
       "    It must be an integer greater or equal than 1.\n",
       "    If set to None, all models are kept on the disc.\n",
       "\n",
       "seed : int, optional (default=1)\n",
       "    Used to seed SMAC. Will determine the output file names.\n",
       "\n",
       "memory_limit : int, optional (3072)\n",
       "    Memory limit in MB for the machine learning algorithm.\n",
       "    `auto-sklearn` will stop fitting the machine learning algorithm if\n",
       "    it tries to allocate more than ``memory_limit`` MB.\n",
       "\n",
       "    **Important notes:**\n",
       "\n",
       "    * If ``None`` is provided, no memory limit is set.\n",
       "    * In case of multi-processing, ``memory_limit`` will be *per job*, so the total usage is\n",
       "      ``n_jobs x memory_limit``.\n",
       "    * The memory limit also applies to the ensemble creation process.\n",
       "\n",
       "include : Optional[Dict[str, List[str]]] = None\n",
       "    If None, all possible algorithms are used.\n",
       "\n",
       "    Otherwise, specifies a step and the components that are included in search.\n",
       "    See ``/pipeline/components/<step>/*`` for available components.\n",
       "\n",
       "    Incompatible with parameter ``exclude``.\n",
       "\n",
       "    **Possible Steps**:\n",
       "\n",
       "    * ``\"data_preprocessor\"``\n",
       "    * ``\"balancing\"``\n",
       "    * ``\"feature_preprocessor\"``\n",
       "    * ``\"classifier\"`` - Only for when when using ``AutoSklearnClasssifier``\n",
       "    * ``\"regressor\"`` - Only for when when using ``AutoSklearnRegressor``\n",
       "\n",
       "    **Example**:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        include = {\n",
       "            'classifier': [\"random_forest\"],\n",
       "            'feature_preprocessor': [\"no_preprocessing\"]\n",
       "        }\n",
       "\n",
       "exclude : Optional[Dict[str, List[str]]] = None\n",
       "    If None, all possible algorithms are used.\n",
       "\n",
       "    Otherwise, specifies a step and the components that are excluded from search.\n",
       "    See ``/pipeline/components/<step>/*`` for available components.\n",
       "\n",
       "    Incompatible with parameter ``include``.\n",
       "\n",
       "    **Possible Steps**:\n",
       "\n",
       "    * ``\"data_preprocessor\"``\n",
       "    * ``\"balancing\"``\n",
       "    * ``\"feature_preprocessor\"``\n",
       "    * ``\"classifier\"`` - Only for when when using ``AutoSklearnClasssifier``\n",
       "    * ``\"regressor\"`` - Only for when when using ``AutoSklearnRegressor``\n",
       "\n",
       "    **Example**:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        exclude = {\n",
       "            'classifier': [\"random_forest\"],\n",
       "            'feature_preprocessor': [\"no_preprocessing\"]\n",
       "        }\n",
       "\n",
       "resampling_strategy : str | BaseCrossValidator | _RepeatedSplits | BaseShuffleSplit = \"holdout\"\n",
       "    How to to handle overfitting, might need to use ``resampling_strategy_arguments``\n",
       "    if using ``\"cv\"`` based method or a Splitter object.\n",
       "\n",
       "    * **Options**\n",
       "        *   ``\"holdout\"`` - Use a 67:33 (train:test) split\n",
       "        *   ``\"cv\"``: perform cross validation, requires \"folds\" in ``resampling_strategy_arguments``\n",
       "        *   ``\"holdout-iterative-fit\"`` - Same as \"holdout\" but iterative fit where possible\n",
       "        *   ``\"cv-iterative-fit\"``: Same as \"cv\" but iterative fit where possible\n",
       "        *   ``\"partial-cv\"``: Same as \"cv\" but uses intensification.\n",
       "        *   ``BaseCrossValidator`` - any BaseCrossValidator subclass (found in scikit-learn model_selection module)\n",
       "        *   ``_RepeatedSplits`` - any _RepeatedSplits subclass (found in scikit-learn model_selection module)\n",
       "        *   ``BaseShuffleSplit`` - any BaseShuffleSplit subclass (found in scikit-learn model_selection module)\n",
       "\n",
       "    If using a Splitter object that relies on the dataset retaining it's current\n",
       "    size and order, you will need to look at the ``dataset_compression`` argument\n",
       "    and ensure that ``\"subsample\"`` is not included in the applied compression\n",
       "    ``\"methods\"`` or disable it entirely with ``False``.\n",
       "\n",
       "resampling_strategy_arguments : Optional[Dict] = None\n",
       "    Additional arguments for ``resampling_strategy``, this is required if\n",
       "    using a ``cv`` based strategy. The default arguments if left as ``None``\n",
       "    are:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        {\n",
       "            \"train_size\": 0.67,     # The size of the training set\n",
       "            \"shuffle\": True,        # Whether to shuffle before splitting data\n",
       "            \"folds\": 5              # Used in 'cv' based resampling strategies\n",
       "        }\n",
       "\n",
       "    If using a custom splitter class, which takes ``n_splits`` such as\n",
       "    `PredefinedSplit <https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn-model-selection-kfold>`_,\n",
       "    the value of ``\"folds\"`` will be used.\n",
       "\n",
       "tmp_folder : string, optional (None)\n",
       "    folder to store configuration output and log files, if ``None``\n",
       "    automatically use ``/tmp/autosklearn_tmp_$pid_$random_number``\n",
       "\n",
       "delete_tmp_folder_after_terminate: bool, optional (True)\n",
       "    remove tmp_folder, when finished. If tmp_folder is None\n",
       "    tmp_dir will always be deleted\n",
       "\n",
       "n_jobs : int, optional, experimental\n",
       "    The number of jobs to run in parallel for ``fit()``. ``-1`` means\n",
       "    using all processors.\n",
       "\n",
       "    **Important notes**:\n",
       "\n",
       "    * By default, Auto-sklearn uses one core.\n",
       "    * Ensemble building is not affected by ``n_jobs`` but can be controlled by the number\n",
       "      of models in the ensemble.\n",
       "    * ``predict()`` is not affected by ``n_jobs`` (in contrast to most scikit-learn models)\n",
       "    * If ``dask_client`` is ``None``, a new dask client is created.\n",
       "\n",
       "dask_client : dask.distributed.Client, optional\n",
       "    User-created dask client, can be used to start a dask cluster and then\n",
       "    attach auto-sklearn to it.\n",
       "\n",
       "disable_evaluator_output: bool or list, optional (False)\n",
       "    If True, disable model and prediction output. Cannot be used\n",
       "    together with ensemble building. ``predict()`` cannot be used when\n",
       "    setting this True. Can also be used as a list to pass more\n",
       "    fine-grained information on what to save. Allowed elements in the\n",
       "    list are:\n",
       "\n",
       "    * ``'y_optimization'`` : do not save the predictions for the\n",
       "      optimization set, which would later on be used to build an ensemble.\n",
       "\n",
       "    * ``model`` : do not save any model files\n",
       "\n",
       "smac_scenario_args : dict, optional (None)\n",
       "    Additional arguments inserted into the scenario of SMAC. See the\n",
       "    `SMAC documentation <https://automl.github.io/SMAC3/main/api/smac.scenario.scenario.html#module-smac.scenario.scenario>`_\n",
       "    for a list of available arguments.\n",
       "\n",
       "get_smac_object_callback : callable\n",
       "    Callback function to create an object of class\n",
       "    `smac.optimizer.smbo.SMBO <https://automl.github.io/SMAC3/main/api/smac.optimizer.smbo.html>`_.\n",
       "    The function must accept the arguments ``scenario_dict``,\n",
       "    ``instances``, ``num_params``, ``runhistory``, ``seed`` and ``ta``.\n",
       "    This is an advanced feature. Use only if you are familiar with\n",
       "    `SMAC <https://automl.github.io/SMAC3/main/index.html>`_.\n",
       "\n",
       "logging_config : dict, optional (None)\n",
       "    dictionary object specifying the logger configuration. If None,\n",
       "    the default logging.yaml file is used, which can be found in\n",
       "    the directory ``util/logging.yaml`` relative to the installation.\n",
       "\n",
       "metadata_directory : str, optional (None)\n",
       "    path to the metadata directory. If None, the default directory\n",
       "    (autosklearn.metalearning.files) is used.\n",
       "\n",
       "metric : Scorer, optional (None)\n",
       "    An instance of :class:`autosklearn.metrics.Scorer` as created by\n",
       "    :meth:`autosklearn.metrics.make_scorer`. These are the `Built-in\n",
       "    Metrics`_.\n",
       "    If None is provided, a default metric is selected depending on the task.\n",
       "\n",
       "scoring_functions : List[Scorer], optional (None)\n",
       "    List of scorers which will be calculated for each pipeline and results will be\n",
       "    available via ``cv_results``\n",
       "\n",
       "load_models : bool, optional (True)\n",
       "    Whether to load the models after fitting Auto-sklearn.\n",
       "\n",
       "get_trials_callback: callable\n",
       "    A callable with the following definition.\n",
       "\n",
       "    * (smac.SMBO, smac.RunInfo, smac.RunValue, time_left: float) -> bool | None\n",
       "\n",
       "    This will be called after SMAC, the underlying optimizer for autosklearn,\n",
       "    finishes training each run.\n",
       "\n",
       "    You can use this to record your own information about the optimization\n",
       "    process. You can also use this to enable a early stopping based on some\n",
       "    critera.\n",
       "\n",
       "    See the example:\n",
       "    :ref:`Early Stopping And Callbacks <sphx_glr_examples_40_advanced_example_early_stopping_and_callbacks.py>`.\n",
       "\n",
       "dataset_compression: Union[bool, Mapping[str, Any]] = True\n",
       "    We compress datasets so that they fit into some predefined amount of memory.\n",
       "    Currently this does not apply to dataframes or sparse arrays, only to raw\n",
       "    numpy arrays.\n",
       "\n",
       "    **NOTE** - If using a custom ``resampling_strategy`` that relies on specific\n",
       "    size or ordering of data, this must be disabled to preserve these properties.\n",
       "\n",
       "    You can disable this entirely by passing ``False`` or leave as the default\n",
       "    ``True`` for configuration below.\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        {\n",
       "            \"memory_allocation\": 0.1,\n",
       "            \"methods\": [\"precision\", \"subsample\"]\n",
       "        }\n",
       "\n",
       "    You can also pass your own configuration with the same keys and choosing\n",
       "    from the available ``\"methods\"``.\n",
       "\n",
       "    The available options are described here:\n",
       "\n",
       "    * **memory_allocation**\n",
       "        By default, we attempt to fit the dataset into ``0.1 * memory_limit``.\n",
       "        This float value can be set with ``\"memory_allocation\": 0.1``.\n",
       "        We also allow for specifying absolute memory in MB, e.g. 10MB is\n",
       "        ``\"memory_allocation\": 10``.\n",
       "\n",
       "        The memory used by the dataset is checked after each reduction method is\n",
       "        performed. If the dataset fits into the allocated memory, any further\n",
       "        methods listed in ``\"methods\"`` will not be performed.\n",
       "\n",
       "        For example, if ``methods: [\"precision\", \"subsample\"]`` and the\n",
       "        ``\"precision\"`` reduction step was enough to make the dataset fit into\n",
       "        memory, then the ``\"subsample\"`` reduction step will not be performed.\n",
       "\n",
       "    * **methods**\n",
       "        We provide the following methods for reducing the dataset size.\n",
       "        These can be provided in a list and are performed in the order as given.\n",
       "\n",
       "        *   ``\"precision\"`` - We reduce floating point precision as follows:\n",
       "            *   ``np.float128 -> np.float64``\n",
       "            *   ``np.float96 -> np.float64``\n",
       "            *   ``np.float64 -> np.float32``\n",
       "\n",
       "        *   ``subsample`` - We subsample data such that it **fits directly into\n",
       "            the memory allocation** ``memory_allocation * memory_limit``.\n",
       "            Therefore, this should likely be the last method listed in\n",
       "            ``\"methods\"``.\n",
       "            Subsampling takes into account classification labels and stratifies\n",
       "            accordingly. We guarantee that at least one occurrence of each\n",
       "            label is included in the sampled set.\n",
       "\n",
       "allow_string_features: bool = True\n",
       "    Whether autosklearn should process string features. By default the\n",
       "    textpreprocessing is enabled.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "cv_results_ : dict of numpy (masked) ndarrays\n",
       "    A dict with keys as column headers and values as columns, that can be\n",
       "    imported into a pandas ``DataFrame``.\n",
       "\n",
       "    Not all keys returned by scikit-learn are supported yet.\n",
       "\n",
       "performance_over_time_ : pandas.core.frame.DataFrame\n",
       "    A ``DataFrame`` containing the models performance over time data. Can be\n",
       "    used for plotting directly. Please refer to the example\n",
       "    :ref:`Train and Test Inputs <sphx_glr_examples_40_advanced_example_pandas_train_test.py>`.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/estimators.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autosklearn.classification.AutoSklearnClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] [2023-02-05 15:43:27,726:Client-AutoML(1):8c4a17e8-a595-11ed-8388-9061aedbab23] 'generator' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ivv101/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/automl.py\", line 899, in fit\n",
      "    ) = _proc_smac.run_smbo()\n",
      "  File \"/home/ivv101/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/smbo.py\", line 446, in run_smbo\n",
      "    metalearning_configurations = self.get_metalearning_suggestions()\n",
      "  File \"/home/ivv101/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/smbo.py\", line 638, in get_metalearning_suggestions\n",
      "    meta_base = MetaBase(\n",
      "  File \"/home/ivv101/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/metalearning/metalearning/meta_base.py\", line 49, in __init__\n",
      "    aslib_reader = aslib_simple.AlgorithmSelectionProblem(\n",
      "  File \"/home/ivv101/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/metalearning/input/aslib_simple.py\", line 35, in __init__\n",
      "    self._read_files()\n",
      "  File \"/home/ivv101/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/metalearning/input/aslib_simple.py\", line 80, in _read_files\n",
      "    read_func(file_)\n",
      "  File \"/home/ivv101/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/metalearning/input/aslib_simple.py\", line 86, in _read_algorithm_runs\n",
      "    if arff_dict[\"attributes\"][0][0].upper() != \"INSTANCE_ID\":\n",
      "TypeError: 'generator' object is not subscriptable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/estimators.py:1448\u001b[0m, in \u001b[0;36mAutoSklearnClassifier.fit\u001b[0;34m(self, X, y, X_test, y_test, feat_type, dataset_name)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;66;03m# remember target type for using in predict_proba later.\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_type \u001b[38;5;241m=\u001b[39m target_type\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeat_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeat_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;66;03m# After fit, a classifier is expected to define classes_\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;66;03m# A list of class labels known to the classifier, mapping each label\u001b[39;00m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;66;03m# to a numerical index used in the model representation our output.\u001b[39;00m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoml_\u001b[38;5;241m.\u001b[39mInputValidator\u001b[38;5;241m.\u001b[39mtarget_validator\u001b[38;5;241m.\u001b[39mclasses_\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/estimators.py:540\u001b[0m, in \u001b[0;36mAutoSklearnEstimator.fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoml_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoml_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_automl()\n\u001b[0;32m--> 540\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoml_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/automl.py:2304\u001b[0m, in \u001b[0;36mAutoMLClassifier.fit\u001b[0;34m(self, X, y, X_test, y_test, feat_type, dataset_name, only_return_configuration_space, load_models)\u001b[0m\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2295\u001b[0m     X: SUPPORTED_FEAT_TYPES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2302\u001b[0m     load_models: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2303\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AutoMLClassifier:\n\u001b[0;32m-> 2304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2306\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2308\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeat_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeat_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2311\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_return_configuration_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_return_configuration_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_classification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/automl.py:962\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[0;34m(self, X, y, task, X_test, y_test, feat_type, dataset_name, only_return_configuration_space, load_models, is_classification)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;66;03m# This will be called before the _fit_cleanup\u001b[39;00m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mexception(e)\n\u001b[0;32m--> 962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_cleanup()\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/automl.py:899\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[0;34m(self, X, y, task, X_test, y_test, feat_type, dataset_name, only_return_configuration_space, load_models, is_classification)\u001b[0m\n\u001b[1;32m    863\u001b[0m resamp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resampling_strategy_arguments\n\u001b[1;32m    864\u001b[0m _proc_smac \u001b[38;5;241m=\u001b[39m AutoMLSMBO(\n\u001b[1;32m    865\u001b[0m     config_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration_space,\n\u001b[1;32m    866\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    892\u001b[0m     trials_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_trials_callback,\n\u001b[1;32m    893\u001b[0m )\n\u001b[1;32m    895\u001b[0m (\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunhistory_,\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrajectory_,\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_budget_type,\n\u001b[0;32m--> 899\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43m_proc_smac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_smbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    901\u001b[0m trajectory_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mget_smac_output_directory_for_run(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seed),\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrajectory.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    904\u001b[0m )\n\u001b[1;32m    905\u001b[0m saveable_trajectory \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28mlist\u001b[39m(entry[:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;241m+\u001b[39m [entry[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mget_dictionary()]\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(entry[\u001b[38;5;241m3\u001b[39m:])\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrajectory_\n\u001b[1;32m    910\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/smbo.py:446\u001b[0m, in \u001b[0;36mAutoMLSMBO.run_smbo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m num_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_num_run\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Initialize some SMAC dependencies\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m metalearning_configurations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metalearning_suggestions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresampling_strategy \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial-cv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial-cv-iterative-fit\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    449\u001b[0m     num_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresampling_strategy_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfolds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/smbo.py:638\u001b[0m, in \u001b[0;36mAutoMLSMBO.get_metalearning_suggestions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_directory):\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata directory: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_directory)\n\u001b[0;32m--> 638\u001b[0m     meta_base \u001b[38;5;241m=\u001b[39m \u001b[43mMetaBase\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m     metafeature_calculation_time_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_walltime_limit \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    643\u001b[0m     metafeature_calculation_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/metalearning/metalearning/meta_base.py:49\u001b[0m, in \u001b[0;36mMetaBase.__init__\u001b[0;34m(self, configuration_space, aslib_directory, logger)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_configuration_space_dict \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     45\u001b[0m     configuration_space\u001b[38;5;241m.\u001b[39mget_default_configuration()\u001b[38;5;241m.\u001b[39mget_dictionary()\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maslib_directory \u001b[38;5;241m=\u001b[39m aslib_directory\n\u001b[0;32m---> 49\u001b[0m aslib_reader \u001b[38;5;241m=\u001b[39m \u001b[43maslib_simple\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAlgorithmSelectionProblem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maslib_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration_space\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetafeatures \u001b[38;5;241m=\u001b[39m aslib_reader\u001b[38;5;241m.\u001b[39mmetafeatures\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm_runs: OrderedDict[\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mstr\u001b[39m, pd\u001b[38;5;241m.\u001b[39mDataFrame\n\u001b[1;32m     55\u001b[0m ] \u001b[38;5;241m=\u001b[39m aslib_reader\u001b[38;5;241m.\u001b[39malgorithm_runs\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/metalearning/input/aslib_simple.py:35\u001b[0m, in \u001b[0;36mAlgorithmSelectionProblem.__init__\u001b[0;34m(self, directory, cs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Read ASLib files\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_files()\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/metalearning/input/aslib_simple.py:80\u001b[0m, in \u001b[0;36mAlgorithmSelectionProblem._read_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m read_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_funcs\u001b[38;5;241m.\u001b[39mget(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_func:\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/p310/lib/python3.10/site-packages/autosklearn/metalearning/input/aslib_simple.py:86\u001b[0m, in \u001b[0;36mAlgorithmSelectionProblem._read_algorithm_runs\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m     84\u001b[0m     arff_dict \u001b[38;5;241m=\u001b[39m arff\u001b[38;5;241m.\u001b[39mload(fh)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43marff_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattributes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSTANCE_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance_id as first attribute is missing in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename)\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arff_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREPETITION\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "cls.fit(df_feat, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_test = train_test_split(df, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp = df_feat.copy()\n",
    "df_inp[df_inp.isna()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use masking nans for RNN such as LSTM!!!\n",
    "# https://www.tensorflow.org/guide/keras/masking_and_padding\n",
    "\n",
    "dense_units = [16]*3\n",
    "\n",
    "dropout_units = [0.3]*3\n",
    "\n",
    "inputs = keras.layers.Input(shape=(20,))\n",
    "\n",
    "x = inputs\n",
    "\n",
    "# x = base_model.layers[1](x)\n",
    "# x = base_model.layers[2](x)\n",
    "\n",
    "x = keras.layers.Normalization()(x)\n",
    "\n",
    "x = keras.layers.Dense(dense_units[0], activation='relu')(x)\n",
    "\n",
    "x = keras.layers.Dropout(dropout_units[0])(x)\n",
    "\n",
    "x = keras.layers.Dense(dense_units[1], activation='relu')(x)\n",
    "\n",
    "x = keras.layers.Dropout(dropout_units[1])(x)\n",
    "\n",
    "x = keras.layers.Dense(dense_units[2], activation='relu')(x)\n",
    "\n",
    "x = keras.layers.Dropout(dropout_units[2])(x)\n",
    "\n",
    "x = keras.layers.Dense(8, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit(df_inp.to_numpy(), y_true,\n",
    "                 epochs=100, \n",
    "                 batch_size=32, \n",
    "                 # validation_data=(padded_docs_test, y_test),\n",
    "                     # verbose=1,\n",
    "                validation_split=0.2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Baseline Embedding model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mod = model.predict(df_inp.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred_mod.round(), \n",
    "                            output_dict=False,\n",
    "                            target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mod.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True, \n",
    "    max_trials=1,\n",
    "    metrics=METRICS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "history = clf.fit(\n",
    "    df_inp,\n",
    "    y_true,\n",
    "    epochs=100,\n",
    "    # callbacks=[tensorboard_callback]\n",
    "    # verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ak.ClassificationHead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ak.ClassificationHead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dig.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_mod.export_model().predict(df_dig.to_numpy()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feat.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aq55Ba1_2NEW"
   },
   "outputs": [],
   "source": [
    "ak_model = ak.TextClassifier(\n",
    "    multi_label=False,\n",
    "    overwrite=True, \n",
    "    max_trials=1,\n",
    "    project_name='ak_model_14_vanilla',\n",
    "    metrics=METRICS,\n",
    "    seed=SEED\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ak.TextClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = ak.Embedding(max_features=20001, pretraining=None, embedding_dim=None, dropout=None, mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak_model.export_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_str = np.array([' '.join(_) for _ in df_dig.to_numpy().astype(str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aq55Ba1_2NEW",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time history = ak_model.fit(data_str, y_true, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Baseline Embedding model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = mlb.transform(predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_true = [[_] for _ in df_test['True_Class']]\n",
    "y_test_true = mlb.transform(y_test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_true, predicted_y, \n",
    "                            target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [layers.Embedding(len(bins)+1, 64, input_length=df_dig.shape[1], mask_zero=True), \n",
    "     layers.LSTM(128),\n",
    "     layers.Dropout(0.2),\n",
    "     layers.Dense(len(classes), activation='softmax')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit(df_dig, y_true,\n",
    "                 epochs=10, \n",
    "                 batch_size=32, \n",
    "                 # validation_data=(padded_docs_test, y_test),\n",
    "                     # verbose=1,\n",
    "                validation_split=0.2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Baseline Embedding model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(len(bins)+1, 1, input_length=df_dig.shape[1], mask_zero=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_array = np.random.randint(1000, size=(32, 10))\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(df_dig)\n",
    "print(output_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True, \n",
    "    max_trials=1,\n",
    "    metrics=METRICS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "history = clf.fit(\n",
    "    df_feat,\n",
    "    y_true,\n",
    "    epochs=100,\n",
    "    # callbacks=[tensorboard_callback]\n",
    "    # verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = clf.export_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary(expand_nested=True, show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_config().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "[_['config'] for _ in base_model.get_config()['layers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ak.StructuredDataInput?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.layers.Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(20,), dtype='float64')\n",
    "x = inputs\n",
    "x = base_model.layers[1](x)\n",
    "x = base_model.layers[2](x)\n",
    "\n",
    "mod_input = keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df_feat.to_numpy() \n",
    "_, _.min(), _.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = mod_input.predict(df_feat)\n",
    "inp, inp.shape, inp.min(), inp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df_feat.to_numpy().astype(np.float32)\n",
    "d, d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.isnan(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0, 5], inp[0, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use masking nans for RNN such as LSTM!!!\n",
    "# https://www.tensorflow.org/guide/keras/masking_and_padding\n",
    "\n",
    "inputs = keras.layers.Input(shape=(20,))\n",
    "\n",
    "x = inputs\n",
    "\n",
    "# x = base_model.layers[1](x)\n",
    "# x = base_model.layers[2](x)\n",
    "\n",
    "x = keras.layers.Normalization()(x)\n",
    "\n",
    "x = keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "x = keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "# x = keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "# x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "x = keras.layers.Dense(8, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dropout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.losses.CategoricalCrossentropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit(df_feat.to_numpy().astype(np.float32), y_true,\n",
    "                 epochs=100, \n",
    "                 batch_size=32, \n",
    "                 # validation_data=(padded_docs_test, y_test),\n",
    "                     # verbose=1,\n",
    "                validation_split=0.2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Baseline Embedding model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = ak.StructuredDataInput()\n",
    "\n",
    "x = input_layer\n",
    "\n",
    "x = ak.Normalization()(x)\n",
    "\n",
    "x = ak.DenseBlock(num_layers=1, num_units=32, activation='relu')(x)\n",
    "\n",
    "x = ak.DenseBlock(num_layers=1, num_units=32, activation='relu')(x)\n",
    "\n",
    "x = ak.DenseBlock(num_layers=1, num_units=8, activation='softmax')(x)\n",
    "\n",
    "clf2 = ak.AutoModel(\n",
    "    inputs=input_layer,\n",
    "    outputs=x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = clf.fit(\n",
    "    df_feat,\n",
    "    y_pred,\n",
    "    epochs=100,\n",
    "    callbacks=[tensorboard_callback]\n",
    "    # verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = clf.export_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.summary(expand_nested=True, show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(input_shape=(20,), dtype='float32'):\n",
    "    \n",
    "    input_layer = layers.Input(shape=input_shape, name='input_1')\n",
    "    \n",
    "    # if encoding is not None:\n",
    "    #     multi_category_encoding = CustomMultiCategoryEncoding(encoding=encoding, name='multi_category_encoding')\n",
    "    #     x = multi_category_encoding(input_layer)\n",
    "    # else:\n",
    "    x = input_layer\n",
    "        \n",
    "    x = layers.Normalization(axis=(-1,), name='normalization')(x)\n",
    "    x = layers.Dense(32, activation='relu', name='dense')(x)\n",
    "    # x = layers.ReLU(dtype=dtype, name='re_lu')(x)\n",
    "    x = layers.Dense(32, activation='relu', name='dense_1')(x)\n",
    "    # x = layers.ReLU(dtype=dtype, name='re_lu_1')(x)\n",
    "    x = layers.Dense(8, activation='softmax', name='dense_2')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=x, name='model')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(df_feat.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.optimizers.SGD(\n",
    "#     learning_rate=0.0001, momentum=0.7, nesterov=False, name='sgd'\n",
    "# )\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit(df_feat, y_true,\n",
    "                 epochs=10, \n",
    "                 batch_size=8, \n",
    "                 # validation_data=(padded_docs_test, y_test),\n",
    "                     # verbose=1,\n",
    "                     validation_split=0.2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0., 0., 1.], [1., 1., 0.]] #[[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
    "cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "cce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.losses.CategoricalCrossentropy??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(df_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = mlb.transform(predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_true = [[_] for _ in df_test['True_Class']]\n",
    "y_test_true = mlb.transform(y_test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_true, predicted_y, \n",
    "                            target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_report?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df_test['True_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = df[features].copy()\n",
    "df2['label'] = df['True_Class']\n",
    "# df2['old_pred'] = df['Class']\n",
    "\n",
    "df2.index = df['CSCv2_name']\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "labels = mlb.fit_transform([[_] for _ in df['True_Class']])\n",
    "classes = mlb.classes_\n",
    "\n",
    "classes, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[features].to_numpy(), labels, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df2['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_pred = mlb.transform([[_] for _ in df2['old_pred']])\n",
    "old_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_report?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels, \n",
    "                            old_pred, \n",
    "                            output_dict=False,\n",
    "                            target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pkl.load(open(f'{tmp_dir}/data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labels(df, labels, in_col='genres', out_col='genres2'):\n",
    "    \n",
    "    if type(labels)==str:\n",
    "        labels = [labels]\n",
    "        \n",
    "    df[out_col] = [sorted(list(set(_).difference(set(labels)))) for _ in df[in_col]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us remove genres that have <1000 entries as well as 'Musical', 'Mystery', and 'Biography' (they were found to be poorly perfoming in training, which makes sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, abund = np.unique(np.concatenate(df['genres'].tolist()), return_counts=True)\n",
    "        \n",
    "to_remove = set(labels[np.where(abund<1000)[0]])\n",
    "to_remove = to_remove.union({'Musical', 'Mystery', 'Biography'})\n",
    "\n",
    "to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_labels(df, to_remove)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# Counter([len(_) for _ in df['genres2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing labels for multi-label classification with Autokeras' TextClassifier model. It appears to be the simplest method that provided good f1 micro scores. Also, it does not require a heavy cleaning of the input such as stemming.\n",
    "\n",
    "### Other models could include Bidirectional LSTM layers, or RoBERTa transformer model. Also one could fine-tune a pretrained model that calculates a semantic similarity between texts on pairs (synopsis, genres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(df['genres2'])\n",
    "classes = mlb.classes_\n",
    "\n",
    "classes, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = df['clean'].to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_input, labels, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aq55Ba1_2NEW"
   },
   "outputs": [],
   "source": [
    "ak_model = ak.TextClassifier(\n",
    "    multi_label=True,\n",
    "    overwrite=True, \n",
    "    max_trials=1,\n",
    "    project_name='ak_model_14_vanilla',\n",
    "    metrics=METRICS,\n",
    "    seed=SEED\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aq55Ba1_2NEW"
   },
   "outputs": [],
   "source": [
    "%time history = ak_model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = ak_model.export_model()\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We chose a threshold of 0.95 for a prediction array normalized by its maximum value in order to allow for multiple genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred = np.where((y_pred.T/y_pred.max(1)).T > 0.95, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(new_y_pred.sum(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1 micro avg is 0.47. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, \n",
    "                            new_y_pred, \n",
    "                            output_dict=False,\n",
    "                            target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(y_test * new_y_pred)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_y_pred.sum(0).astype(int), np.unique(new_y_pred.sum(1).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.save(f'{out_dir}/tf_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to choose similar moview, we compute predictions for each movie with revenue > $10 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input_pred = tf_model.predict(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['revenue'] > 1e7\n",
    "len(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[mask]\n",
    "text_input_pred2 = text_input_pred[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data = df2[['name', 'year', 'genres']].to_dict(orient='list')\n",
    "out_data['pred'] = text_input_pred2\n",
    "\n",
    "out_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump([classes, out_data], open(f'{out_dir}/aux_data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking that spoiler database also produces a good f1 micro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = pkl.load(open(f'{tmp_dir}/df_imdb.pkl', 'rb'))\n",
    "df_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_labels = mlb.transform(df_imdb['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf_model.predict(df_imdb['clean'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred = np.where((y_pred.T/y_pred.max(1)).T > 0.95, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "Counter(new_y_pred.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(imdb_labels, \n",
    "                            new_y_pred, \n",
    "                            output_dict=False,\n",
    "                            target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_genre = lambda y_pred : np.floor((y_pred.T/y_pred.T.max(0)).T).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# bins = np.arange(df_feat.min().min(), df_feat.max().max(), 0.1)\n",
    "\n",
    "# df_dig = df_feat.apply(lambda x : np.digitize(x, bins))\n",
    "# df_dig[df_feat.isna()] = 0\n",
    "\n",
    "# # len(bins)\n",
    "\n",
    "# input_layer = ak.Input()\n",
    "\n",
    "# x = input_layer\n",
    "\n",
    "# x = ak.Embedding(max_features=len(bins)+1, embedding_dim=None, pretraining='random')(x)\n",
    "\n",
    "# x = ak.RNNBlock()(x)\n",
    "\n",
    "# # x = ak.DenseBlock()(x)\n",
    "\n",
    "# x = ak.ClassificationHead()(x)\n",
    "\n",
    "# rnn_mod = ak.AutoModel(\n",
    "#     inputs=[input_layer],\n",
    "#     outputs=[x],\n",
    "#     project_name='rnn_model',\n",
    "#     max_trials=1,\n",
    "#     seed=SEED,\n",
    "#     overwrite=True\n",
    "# )\n",
    "\n",
    "# hist = rnn_mod.fit(df_dig.to_numpy(), y_true, \n",
    "#                    validation_split=0.2,\n",
    "#                    epochs=100, \n",
    "#                    batch_size=128)\n",
    "\n",
    "# rnn_mod.predict(df_dig.to_numpy()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Plx'].apply(lambda x : np.log10()).hist(bins=100, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['Plx']>15]['True_Class']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_classification",
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/autokeras/blob/master/docs/ipynb/text_classification.ipynb",
     "timestamp": 1674128743914
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:autogluon]",
   "language": "python",
   "name": "conda-env-autogluon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
